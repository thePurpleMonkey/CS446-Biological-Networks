{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 26:  Bayesian Networks\n",
    "## Infer a Bayesian network from a matrix of discretized phospho-flow cytometry data.\n",
    "### Based on supplementary data from the 2005 article by Karen Sachs et al. (Science v308, 2005). \n",
    "\n",
    "In this class exercise, we will use the fundamental theorem for the likelihood of a Bayesian network structure for categorical variables, in order to score the posterior probability of the network shown in the Sachs et al. article (Figure 3A) vs. the phospho-flow cytometry data that the same authors provided in their supplementary data. The phospho-flow cytometry data have been already discretized for you (see \"class26_bayesnet_dataprep_R.ipynb\").  We will need to implement a single-vertex log-likelihood function using Theorem 1 from the article by Cooper & Herskovits in *Machine Learning* (volume 9, pages 309-347, 1992)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the tab-delimited data file of discretized phosphoprotein expression data (12 columns; first 11 columns are the expression levels -- \"low\", \"medium\", \"high\"; last column is the experiment identifier for the row; there are nine experiments). Print out the first six lines of the data frame, so you can see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>praf</th>\n",
       "      <th>pmek</th>\n",
       "      <th>plcg</th>\n",
       "      <th>PIP2</th>\n",
       "      <th>PIP3</th>\n",
       "      <th>p44.42</th>\n",
       "      <th>pakts473</th>\n",
       "      <th>PKA</th>\n",
       "      <th>PKC</th>\n",
       "      <th>P38</th>\n",
       "      <th>pjnk</th>\n",
       "      <th>expt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>1_cd3cd28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>1_cd3cd28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>1_cd3cd28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>1_cd3cd28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>1_cd3cd28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>1_cd3cd28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     praf    pmek    plcg PIP2    PIP3  p44.42 pakts473     PKA     PKC  \\\n",
       "0     low     low     low  low    high     low      low  medium  medium   \n",
       "1     low     low  medium  low     low  medium   medium  medium     low   \n",
       "2  medium    high  medium  low  medium  medium   medium  medium  medium   \n",
       "3  medium    high  medium  low     low     low      low  medium  medium   \n",
       "4     low  medium     low  low  medium  medium   medium     low     low   \n",
       "5     low     low  medium  low     low  medium   medium  medium  medium   \n",
       "\n",
       "      P38    pjnk       expt  \n",
       "0    high    high  1_cd3cd28  \n",
       "1     low    high  1_cd3cd28  \n",
       "2  medium  medium  1_cd3cd28  \n",
       "3  medium  medium  1_cd3cd28  \n",
       "4  medium    high  1_cd3cd28  \n",
       "5    high    high  1_cd3cd28  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "g_discret_data = pandas.read_csv(\"shared/sachs_data_discretized.txt\",\n",
    "                                 sep=\"\\t\")\n",
    "g_discret_data.head(n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a log likelihood function for the vertex degree distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def log_prob_network_prior(network):\n",
    "    return numpy.sum(numpy.log(numpy.power(1 + numpy.sum(network, axis=0) + numpy.sum(network, axis=1),-2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a vectorized log-factorial function, since it doesn't seem to be a builtin in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.special\n",
    "\n",
    "def lfactorial(n):\n",
    "    return scipy.special.gammaln(n+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a log likelihood function for a single vertex, based on Theorem 1 in the 1992 article in *Machine Learning* by Cooper & Herskovits. Note:  we are using igraph's adjacency matrix format which is the transpose of Newman's adjacency matrix definition!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def log_likelihood_network_vertex(network, vertex, discret_data):\n",
    "    # network is a NxN numpy matrix (N = 11 vertices)\n",
    "    # vertex is an integer\n",
    "    # discret_data is \"g_discret_data\" (N = 11 vertices, M = 7466 samples)\n",
    "    parents_vertex = numpy.where(network[:,vertex]==1)[0].tolist()\n",
    "    all_vertices = parents_vertex.copy()\n",
    "    all_vertices.append(vertex)\n",
    "    df1 = discret_data[all_vertices]\n",
    "\n",
    "    # change the name of the vertex column to \"vertex\"\n",
    "    df1_column_names = df1.columns.tolist()\n",
    "    df1_column_names[len(parents_vertex)] = \"vertex\"\n",
    "    df1.columns = df1_column_names\n",
    "\n",
    "    # count the data, grouped by all columns (parents & vertex)\n",
    "    df1 = df1.groupby(df1.columns.values.tolist()).size().reset_index(name='count')\n",
    "    \n",
    "    # make a new column called \"count factorial\" that is the log of the factorial of the count\n",
    "    df1[\"countfactorial\"] = lfactorial(df1[\"count\"].values)\n",
    "    \n",
    "    # drop the \"count\" column, as we no longer need it\n",
    "    df1 = df1.drop(\"count\", 1)\n",
    "    \n",
    "    if len(parents_vertex) > 0:\n",
    "        nijk = df1.groupby(by=df1.columns[list(range(0,len(parents_vertex)))].tolist())[\"countfactorial\"].sum().as_matrix()\n",
    "        df3 = discret_data[parents_vertex]\n",
    "        nij = math.log(2) - lfactorial(2 + df3.groupby(df3.columns.values.tolist()).size().values)\n",
    "        llh_res = numpy.sum(nij + nijk)\n",
    "    else:\n",
    "        M = discret_data.shape[0]\n",
    "        llh_res = math.log(2) - lfactorial(M + 2) + numpy.sum(df1[\"countfactorial\"].values)\n",
    "    return llh_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a log-posterior-probability function for the whole graph, using the per-vertex likelihood and the network structure prior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_posterior_prob_network(network, discret_data):\n",
    "    Nvert = network.shape[1]\n",
    "    lpvert_values = []\n",
    "    for i in range(0, Nvert):\n",
    "        lpvert_value = log_likelihood_network_vertex(network, i, discret_data)\n",
    "        lpvert_values.append(lpvert_value)\n",
    "    return log_prob_network_prior(network) + numpy.sum(numpy.array(lpvert_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an adjacency matrix for the \"real\" network shown in Fig. 3A of the Sachs et al. article (not including the \"missed\" edges which are the dotted arcs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          praf  pmek  plcg  PIP2  PIP3  p44.42  pakts473  PKA  PKC  P38  pjnk\n",
      "praf       0.0   1.0   0.0   0.0   0.0     0.0       0.0  0.0  0.0  0.0   0.0\n",
      "pmek       0.0   0.0   0.0   0.0   0.0     1.0       0.0  0.0  0.0  0.0   0.0\n",
      "plcg       0.0   0.0   0.0   1.0   1.0     0.0       0.0  0.0  0.0  0.0   0.0\n",
      "PIP2       0.0   0.0   0.0   0.0   0.0     0.0       0.0  0.0  0.0  0.0   0.0\n",
      "PIP3       0.0   0.0   0.0   1.0   0.0     0.0       0.0  0.0  0.0  0.0   0.0\n",
      "p44.42     0.0   0.0   0.0   0.0   0.0     0.0       1.0  0.0  0.0  0.0   0.0\n",
      "pakts473   0.0   0.0   0.0   0.0   0.0     0.0       0.0  0.0  0.0  0.0   0.0\n",
      "PKA        1.0   1.0   0.0   0.0   0.0     1.0       1.0  0.0  0.0  1.0   1.0\n",
      "PKC        1.0   1.0   0.0   0.0   0.0     0.0       0.0  1.0  0.0  1.0   1.0\n",
      "P38        0.0   0.0   0.0   0.0   0.0     0.0       0.0  0.0  0.0  0.0   0.0\n",
      "pjnk       0.0   0.0   0.0   0.0   0.0     0.0       0.0  0.0  0.0  0.0   0.0\n"
     ]
    }
   ],
   "source": [
    "real_network_adj = numpy.zeros(shape=[11,11])\n",
    "molec_names = g_discret_data[list(range(0,11))].columns.values    \n",
    "real_network_adj = pandas.DataFrame(real_network_adj, index=molec_names, columns=molec_names)\n",
    "real_network_adj[\"PKA\"][\"PKC\"] = 1\n",
    "real_network_adj[\"praf\"][\"PKC\"] = 1\n",
    "real_network_adj[\"pjnk\"][\"PKC\"] = 1\n",
    "real_network_adj[\"P38\"][\"PKC\"] = 1\n",
    "real_network_adj[\"pjnk\"][\"PKA\"] = 1\n",
    "real_network_adj[\"P38\"][\"PKA\"] = 1\n",
    "real_network_adj[\"praf\"][\"PKA\"] = 1\n",
    "real_network_adj[\"pmek\"][\"PKA\"] = 1\n",
    "real_network_adj[\"p44.42\"][\"PKA\"] = 1  # p44.42 = ERK\n",
    "real_network_adj[\"pakts473\"][\"PKA\"] = 1\n",
    "real_network_adj[\"pakts473\"][\"p44.42\"] = 1\n",
    "real_network_adj[\"pmek\"][\"PKC\"] = 1\n",
    "real_network_adj[\"pmek\"][\"praf\"] = 1\n",
    "real_network_adj[\"p44.42\"][\"pmek\"] = 1\n",
    "real_network_adj[\"PIP2\"][\"plcg\"] = 1\n",
    "real_network_adj[\"PIP3\"][\"plcg\"] = 1\n",
    "real_network_adj[\"PIP2\"][\"PIP3\"] = 1\n",
    "print(real_network_adj)\n",
    "real_network_adj = real_network_adj.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an igraph network out of the adjacency matrix that you just created, and print the network summary and plot the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IGRAPH D--- 11 17 -- '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import igraph\n",
    "real_network_igraph = igraph.Graph.Adjacency(real_network_adj.tolist())\n",
    "real_network_igraph.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the log posterior probability of the real network from Sachs *et al.* Figure 3A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-84131.03111133902"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_posterior_prob_network(real_network_adj, g_discret_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 10000 random rewirings of the network -- eliminating any rewired digraphs that contain cycles -- and for each randomly rewired DAG, histogram the log ratio of the \"real\" network's posterior probability to the posterior probabilities of each of the random networks. Does it appear that the published network is pretty close to the maximum *a posteriori* (MAP) estimate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of skipped graphs: 4072\n",
      "Ratio of skipped to used graphs: 0.4072\n"
     ]
    }
   ],
   "source": [
    "random_network = real_network_igraph.copy()\n",
    "\n",
    "skipped = 0\n",
    "data = []\n",
    "\n",
    "for i in range(10000):\n",
    "    random_network.rewire()\n",
    "    \n",
    "    if not random_network.is_dag():\n",
    "        skipped += 1\n",
    "        continue\n",
    "        \n",
    "    # Something goes here.\n",
    "        \n",
    "        \n",
    "print(\"Number of skipped graphs:\", skipped)\n",
    "print(\"Ratio of skipped to used graphs:\", skipped/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
